# Multi-SWE-Bench å…¨æµç¨‹æ‰§è¡Œæ¸…å•

ä¸‹é¢ä¸ºç»è¿‡æ•´ç†ä¸éªŒè¯çš„â€œæ­£ç¡®ã€å¯å¤ç°â€çš„å…¨æµç¨‹ï¼ˆå››æ­¥ï¼‰ï¼ŒåŒ…å«å¿…è¦å‰ç½®æ¡ä»¶ã€æ¯æ­¥å‘½ä»¤ã€è¾“å‡ºæ ¡éªŒä¸å¸¸è§æ’æŸ¥å»ºè®®ã€‚

---

## å‰ç½®æ¡ä»¶ ğŸ”§

- å®‰è£… Dockerï¼ˆå¹¶ç¡®ä¿ Docker å¯è¿è¡Œï¼‰
- Python ç¯å¢ƒï¼šå»ºè®®æ‰§è¡Œ `make install`ï¼ˆæˆ– `make install-dev`ï¼‰ä»¥å®‰è£…ä¾èµ–ï¼š
  - `make install` â†’ å®‰è£… package
  - `make install-dev` â†’ å®‰è£…å¼€å‘ä¾èµ–ï¼ˆå¯é€‰ï¼‰
- å¯é€‰ï¼šé¢„ä¸‹è½½é•œåƒï¼ˆåŠ é€Ÿè¯„æµ‹ï¼‰ï¼š
  - macOS / Linux: `bash scripts/download_images.sh scripts/images_mini.txt`
- è‹¥éœ€è¦ä» GitHub æŠ“å–æ•°æ®ï¼šå‡†å¤‡ GitHub tokenï¼ˆç”¨äº `gen_raw_dataset.sh` / collect è„šæœ¬ï¼‰

---

## å…¨æµç¨‹é¡ºåºï¼ˆæŒ‰åºæ‰§è¡Œï¼‰ ğŸ“‹

> [!TIP]
> **æ–°åŠŸèƒ½**ï¼šç°åœ¨å¯ä»¥ä½¿ç”¨æ ¹ç›®å½•ä¸‹çš„ `./entry.sh` è„šæœ¬é€šè¿‡äº¤äº’å¼èœå•å¿«é€Ÿæ‰§è¡Œä»¥ä¸‹å¸¸ç”¨æ­¥éª¤ã€‚

1) **Step1 â€” ç”Ÿæˆ Raw Datasetï¼ˆå¿…é¡»æœ€å…ˆæ‰§è¡Œï¼‰**
- ç›®çš„ï¼šä» GitHub æ‹‰å– PR å¹¶æ•´åˆä¸º `*_raw_dataset.jsonl`
- ä¸»è¦è„šæœ¬ï¼š
  - ç”Ÿæˆ PR æ•°æ®ï¼š
    - ä¼ ç»Ÿè„šæœ¬ï¼š`./scripts/gen_raw_dataset.sh <owner/repo>`
    - GraphQL è„šæœ¬ (æ›´ç¨³å®š/é«˜æ•ˆ)ï¼š`./scripts/new_gen_raw_dataset_graphql.sh -l <lang> -s <min_stars>`
    - æ‰¹é‡ç”Ÿæˆï¼š`./data_pipeline/gen_all_raw_datasets_new.sh`
  - è¡¥å…¨å¹¶åˆ†ç±»ï¼š`./scripts/collect_raw_dataset.sh`
- è¾“å‡ºï¼š`data/raw_datasets/<owner__repo>_raw_dataset.jsonl`
- æ ¡éªŒï¼šç¡®è®¤ `data/raw_datasets` ä¸‹å­˜åœ¨ `*_raw_dataset.jsonl`

1.1) **Step1.1 â€” æ•°æ®è¿‡æ»¤ä¸ç²¾ç‚¼ï¼ˆå¯é€‰ï¼‰**
- ç›®çš„ï¼šç­›é€‰ç‰¹å®šç±»åˆ«ï¼ˆå¦‚ Bug Fix, Performanceï¼‰æˆ–é™åˆ¶ patch å¤§å°
- è„šæœ¬ï¼š`./scripts/filter_raw_dataset.sh -i <input_dir> -o <output_dir> [options]`
- ç‰¹è‰²ï¼š
    - æ”¯æŒäº¤äº’å¼èœå•ï¼ˆä¸å¸¦å‚æ•°è¿è¡Œï¼‰ã€‚
    - é¢„è®¾æ¨¡å¼ï¼šNew Feature, Bug Fix, Edge Case, Performanceã€‚
    - Patch è¿‡æ»¤ï¼šä½¿ç”¨ `-p <bytes>` æŒ‡å®šæœ€å°è¡¥ä¸å¤§å°ï¼ˆä»…è®¡ç®—ä»£ç éƒ¨åˆ†ï¼‰ã€‚


2) **Step2 â€” ç”Ÿæˆ Repo Docker ä¸è„šæœ¬å¹¶æ„å»º datasetï¼ˆå¯ä¸ Step3 å¹¶è¡Œï¼‰**
- ç›®çš„ï¼šä¸ºæ¯ repo ç”Ÿæˆ `Dockerfile`ã€`prepare.sh`ã€`test.sh`ï¼Œå¹¶ç”Ÿæˆ `*_dataset.jsonl`
- ä¸»è¦è„šæœ¬ï¼š
  - è‡ªåŠ¨ç”Ÿæˆä»“åº“è„šæœ¬å¹¶æ„å»º datasetï¼ˆå•æ–‡ä»¶æˆ–ç›®å½•ï¼‰ï¼š
    `./scripts/unify_repo_scripts.sh data/raw_datasets/*_raw_dataset.jsonl`
  - å•æ–‡ä»¶æ„å»ºï¼ˆæ›¿ä»£æ–¹å¼ï¼‰ï¼š`./data_pipeline/build_dataset.sh <raw_dataset.jsonl>`
- è¾“å‡ºï¼š`data/repos/<owner__repo>/...` ä»¥åŠ `data/datasets/<base>_dataset.jsonl`
- æ ¡éªŒï¼šç¡®è®¤ `data/datasets/<base>_dataset.jsonl` å­˜åœ¨


3) **Step 3 â€” ç”Ÿæˆ Patchï¼ˆå¯ä¸ Step2 å¹¶è¡Œï¼‰**
- ç›®çš„ï¼šä½¿ç”¨ LLM æˆ– Agent å·¥å…· from raw dataset æå–å¹¶ç”Ÿæˆæœ€ç»ˆ patches JSONL
- è„šæœ¬ A (SWE-Agent)ï¼š`./scripts/run_patch.sh data/raw_datasets/<base>_raw_dataset.jsonl`
  - å†…éƒ¨æµç¨‹ï¼š`run_extract_raw_dataset.sh` â†’ `run_sweagent_for_jsonl.sh` â†’ `gen_patches_jsonl.sh`
- è„šæœ¬ B (Massgen)ï¼š`./scripts/run_massgen_for_jsonl.sh <work-dir> <jsonl_path>`
  - ç›®çš„ï¼šåˆ©ç”¨ `massgen` æ‰¹é‡ç”Ÿæˆ patch
- è¾“å‡ºï¼š`data/patches/<base>_patch.jsonl` æˆ–æŒ‡å®šç›®å½•ä¸‹çš„ `.patch` æ–‡ä»¶
- æ ¡éªŒï¼šå»ºè®®æ‰§è¡Œ Patch Quality Checkï¼ˆè§ä¸‹æ–‡ï¼‰

4) **Step 4 â€” Patch Quality Checkï¼ˆè´¨é‡æ ¡éªŒï¼Œå¯é€‰ä½†å»ºè®®ï¼‰**
- ç›®çš„ï¼šåœ¨æ‰§è¡Œå®Œæ•´ Evaluation å‰ï¼Œå…ˆå¯¹ç”Ÿæˆçš„ patch è¿›è¡Œé™æ€æ‰«æä¸è¯„åˆ†
- è„šæœ¬ï¼š
  - æ‰«ææ–‡ä»¶ï¼š`./scripts/semgrep_scan.sh <patch_file> <output_json>`
  - è¯„åˆ†åˆ†æï¼š`./scripts/analyze_patch.sh <semgrep_result.json>`
- è¾“å‡ºï¼šSemgrep æ‰«æç»“æœä¸è´¨é‡è¯„åˆ†æŠ¥å‘Šï¼ˆS/A/B/C/F çº§ï¼‰

5) **Step 5 â€” æ‰§è¡Œ Evaluationï¼ˆå¿…é¡»ç­‰å¾… Step2 + Step3 å®Œæˆï¼‰**
- è„šæœ¬ï¼š`./scripts/run_full_pipeline.sh data/raw_datasets/<base>_raw_dataset.jsonl`
  - è¦æ±‚ï¼š`data/patches/<base>_patch.jsonl` ä¸ `data/datasets/<base>_dataset.jsonl` å·²å­˜åœ¨
  - å†…éƒ¨è°ƒç”¨ï¼š`./data_pipeline/run_evaluation.sh` â†’ Python: `python -m multi_swe_bench.harness.run_evaluation --config <config.json>`
- è¾“å‡ºï¼š`data/output/`ï¼ˆä¸­é—´ï¼‰ä¸ `data/final_output/`ï¼ˆæœ€ç»ˆæŠ¥å‘Šï¼‰
- æ ¡éªŒï¼šæŸ¥çœ‹ `final_report.json` ä¸ `data/final_output/` ä¸­çš„æŠ¥å‘Šä¸æ—¥å¿—

6) **Step 6 â€” è®­ç»ƒæ•°æ®æå–ï¼ˆç”¨äºæ¨¡å‹å¾®è°ƒï¼‰**
- ç›®çš„ï¼šå°†å¤„ç†å¥½çš„æ•°æ®é›†è½¬æ¢ä¸º LLM è®­ç»ƒæ ¼å¼ï¼ˆJSONï¼‰
- è„šæœ¬ï¼š`./scripts/extract_training_data.sh <input_path> <output_file>`
- åŠŸèƒ½ï¼šæ”¯æŒå¤„ç†å•ä¸ªæ–‡ä»¶æˆ–æ•´ä¸ªç›®å½•ï¼Œè‡ªåŠ¨åˆå¹¶å¹¶è¿›è¡ŒåŒå‘è½¬æ¢ï¼ˆPR->Patch, Patch->PRï¼‰ã€‚

---

## å¹¶è¡Œç­–ç•¥ä¸å¿«é€Ÿè¿è¡Œå»ºè®® âš¡

- **Step2 ä¸ Step3 å¯å¹¶è¡Œ**ï¼ˆä¸¤è€…ä»…ä¾èµ– Step1ï¼‰ï¼š

```
./scripts/unify_repo_scripts.sh data/raw_datasets/*_raw_dataset.jsonl &   # Step2
./scripts/run_patch.sh data/raw_datasets/*_raw_dataset.jsonl &           # Step3
wait
./scripts/run_full_pipeline.sh data/raw_datasets/*_raw_dataset.jsonl      # Step4
```

- è‹¥å¤„ç†å¤šä¸ª raw_datasetï¼Œå¯ä½¿ç”¨ `./scripts/run_all_pipeline.sh`ï¼ˆä¼šéå† `data/raw_datasets/*_raw_dataset.jsonl` å¹¶ä¾æ¬¡è°ƒç”¨ `run_full_pipeline.sh`ï¼‰

---

## å¸¸è§é”™è¯¯ & è§£å†³è¦ç‚¹ âš ï¸

- **æ‰¾ä¸åˆ° `*_raw_dataset.jsonl`** â†’ æ£€æŸ¥ `./scripts/gen_raw_dataset.sh` / `./scripts/collect_raw_dataset.sh` æ˜¯å¦æˆåŠŸæ‰§è¡Œå¹¶å†™å…¥
- **`patch JSONL not found` æˆ– `dataset JSONL not found`** â†’ æŒ‰é¡ºåºå…ˆç”Ÿæˆ Step2/Step3 çš„äº§ç‰©
- **Docker build failed (code 127)** â†’ æ£€æŸ¥ `prepare.sh` æƒé™ä¸ Dockerfile æ˜¯å¦å®‰è£… `bash`; å»ºè®®åœ¨ Dockerfile ä¸­æ·»åŠ ï¼š
  ```dockerfile
  RUN chmod +x /home/prepare.sh
  RUN apk add --no-cache bash  # æˆ– apt-get install -y bash
  ```
- **JSONDecodeError / Invalid control character** â†’ ä½¿ç”¨ `jq -c` æ¸…æ´—/æ ¡éªŒ JSONL

---

## å¸¸ç”¨å¿«é€Ÿå‘½ä»¤æ±‡æ€» ğŸ§­

- Step1:
  - `./scripts/gen_raw_dataset.sh owner/repo`
  - `./scripts/new_gen_raw_dataset_graphql.sh -l Python -s 10000`
  - æ‰¹é‡ç”Ÿæˆ (GraphQL): `./data_pipeline/gen_all_raw_datasets_new.sh`
  - `./scripts/collect_raw_dataset.sh`
  - æ•°æ®è¿‡æ»¤: `./scripts/filter_raw_dataset.sh -i ./raw_ds -o ./filtered -p 1024`
  - ç”Ÿæˆè®­ç»ƒæ•°æ®: `./scripts/extract_training_data.sh data/datasets output.json`
- äº¤äº’å¼å…¥å£:
  - `bash entry.sh`
- Step2:
  - `./scripts/unify_repo_scripts.sh data/raw_datasets/*_raw_dataset.jsonl`
  - æˆ–å•æ–‡ä»¶ï¼š`./data_pipeline/build_dataset.sh <raw_dataset.jsonl>`
  - RepoLaunch å‡†å¤‡ï¼š`./scripts/gen_repolaunch.sh <org> <repo> <instance_id> <language>`
- Step3:
  - SWE-Agent: `./scripts/run_patch.sh data/raw_datasets/<base>_raw_dataset.jsonl`
  - Massgen: `./scripts/run_massgen_for_jsonl.sh <work-dir> <jsonl_path>`
- Step4 (Quality Check):
  - `./scripts/semgrep_scan.sh <patch_file> <output_json>`
  - `./scripts/analyze_patch.sh <output_json>`
  - æ‰¹é‡åˆ†æ: `./scripts/batch_analyze_patches.sh <patch_dir> [result_file]`
  - æ‰¹é‡åˆ†æ (CSV): `./scripts/batch_patch_analysis.sh <patch_dir> [result_csv]`
- Step5:
  - `./scripts/run_full_pipeline.sh data/raw_datasets/<base>_raw_dataset.jsonl`
- æ‰¹é‡è¿è¡Œæ‰€æœ‰ raw datasets:
  - `./scripts/run_all_pipeline.sh`

---
